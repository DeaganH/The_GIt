{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E-c-En-train.csv')\n",
    "df_test = pd.read_csv('E-c-En-dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Tweets per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>no. of tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>2602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>love</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>optimism</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surprise</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trust</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion  no. of tweets\n",
       "0          anger           2544\n",
       "1   anticipation            978\n",
       "2        disgust           2602\n",
       "3           fear           1242\n",
       "4            joy           2477\n",
       "5           love            700\n",
       "6       optimism           1984\n",
       "7      pessimism            795\n",
       "8        sadness           2008\n",
       "9       surprise            361\n",
       "10         trust            357"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.drop(['ID', 'Tweet'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_new.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['Emotion', 'no. of tweets'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.029833284586136297\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df[(df['anger']==0) & (df['anticipation']==0) & (df['disgust']==0) & (df['fear']== 0) & (df['joy']==0) & (df['love']==0) & (df['optimism']==0) & (df['pessimism']==0) & (df['sadness']==0) & (df['surprise']==0) & (df['trust']==0)]) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.01580135440180587\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df_test[(df_test['anger']==0) & (df_test['anticipation']==0) & (df_test['disgust']==0) & (df_test['fear']== 0) & (df_test['joy']==0) & (df_test['love']==0) & (df_test['optimism']==0) & (df_test['pessimism']==0) & (df_test['sadness']==0) & (df_test['surprise']==0) & (df_test['trust']==0)]) / len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ‚ÄúWorry is a down payment on a problem you may never have'. ¬†Joyce Meyer.  #motivation #leadership #worry                        \n",
       "1    Whatever you decide to do make sure it makes you #happy.                                                                        \n",
       "2    @Max_Kellerman  it also helps that the majority of NFL coaching is inept. Some of Bill O'Brien's play calling was wow, ! #GOPATS\n",
       "3    Accept the challenges so that you can literally even feel the exhilaration of victory.' -- George S. Patton üê∂                   \n",
       "4    My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs                              \n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df['Tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Function for converting emojis into words\n",
    "def convert_emojis(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].map(lambda com : convert_emojis(com))\n",
    "df_test['Tweet'] = df_test['Tweet'].map(lambda com : convert_emojis(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    #converts to lower case\n",
    "    text = text.lower()\n",
    "    # Remove all the special characters\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    # removes numbers\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text) \n",
    "    # remove all single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # substitutes _ with a space\n",
    "    text = re.sub('_', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    #removes blank space at start of text\n",
    "    text = text.strip(' ')\n",
    "    # lemmatizer\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].map(lambda com : clean_text(com))\n",
    "df_test['Tweet'] = df_test['Tweet'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    making that yearly transition from excited and hopeful college returner to sick and exhausted pessimist college                                    \n",
       "11    and it hard to dance with devil on your back nso shake him off                                                                                     \n",
       "12    tiller and breezy should do collab album rapping and singing prolly be fire                                                                        \n",
       "13    to the girl that just hit my car not only did she get lucky no scratch but also from being spared the wrath of sleep deprived kait upside down face\n",
       "14    bt uk broadband is shocking regretting signing up now angry shouldofgonewithvirgin                                                                 \n",
       "15    people you need to look up the definition of protest what you are doing is not protesting is called vandalism angry stop                           \n",
       "16    bitchesthecat look at those teef growl                                                                                                             \n",
       "17    star trek online has update to download oh fuming yay                                                                                              \n",
       "18    the bitter the battle the sweeter the victory                                                                                                      \n",
       "19    cant stop finished dejected luckily no one is in the bathroom so go to stall and wait until my pants are dry                                       \n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test data frames were used as is\n",
    "\n",
    "train = df\n",
    "test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838,)\n",
      "(886,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.Tweet\n",
    "X_test = test.Tweet\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create categories to iterate over\n",
    "categories = ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created test DF with no values to save predicted probabilities for each emotion\n",
    "\n",
    "test_df_no_values = pd.read_csv('Test_English_no_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@RanaAyyub @rajnathsingh Oh, hidden revenge and anger...I rememberthe time,she rebutted you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm doing all this to make sure you smiling down on me bro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if not then #teamchristine bc all tana has done is provoke her by tweeting shady shit and trying to be a hard bitch begging for a fight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a #great start for #beginners to jump into auto #trading. PROFITABLE FX EA will give you full support, manuals &amp;amp; Team Viewer support.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My best friends driving for the first time with me in the car #terrifying</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey @SuperValuIRL #Fields in #skibbereen give your online delivery service a horrible name. 1.5 hours late on the 1 hour delivery window.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why have #Emmerdale had to rob #robron of having their first child together for that vile woman/cheating sl smh #bitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@ThomasEWoods I would like to hear a podcast of you going off refuting her entire article. Extra indignation please.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If I have to hear one more time how I am intimidate men... I'm going to explode! Why are guys these days so pussified?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depression sucksüòî</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             Tweet  \\\n",
       "0  @RanaAyyub @rajnathsingh Oh, hidden revenge and anger...I rememberthe time,she rebutted you.                                                      \n",
       "1  I'm doing all this to make sure you smiling down on me bro                                                                                        \n",
       "2  if not then #teamchristine bc all tana has done is provoke her by tweeting shady shit and trying to be a hard bitch begging for a fight           \n",
       "3  It is a #great start for #beginners to jump into auto #trading. PROFITABLE FX EA will give you full support, manuals &amp; Team Viewer support.   \n",
       "4  My best friends driving for the first time with me in the car #terrifying                                                                         \n",
       "5  Hey @SuperValuIRL #Fields in #skibbereen give your online delivery service a horrible name. 1.5 hours late on the 1 hour delivery window.         \n",
       "6  Why have #Emmerdale had to rob #robron of having their first child together for that vile woman/cheating sl smh #bitter                           \n",
       "7  @ThomasEWoods I would like to hear a podcast of you going off refuting her entire article. Extra indignation please.                              \n",
       "8  If I have to hear one more time how I am intimidate men... I'm going to explode! Why are guys these days so pussified?                            \n",
       "9  depression sucksüòî                                                                                                                                 \n",
       "\n",
       "   anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "1 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "2 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "3 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "4 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "5 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "6 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "7 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "8 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "9 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "\n",
       "   sadness  surprise  trust  \n",
       "0 NaN      NaN       NaN     \n",
       "1 NaN      NaN       NaN     \n",
       "2 NaN      NaN       NaN     \n",
       "3 NaN      NaN       NaN     \n",
       "4 NaN      NaN       NaN     \n",
       "5 NaN      NaN       NaN     \n",
       "6 NaN      NaN       NaN     \n",
       "7 NaN      NaN       NaN     \n",
       "8 NaN      NaN       NaN     \n",
       "9 NaN      NaN       NaN     "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_no_values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: anger\n",
      "Test accuracy: 0.7957110609480813\n",
      "Emotion: anticipation\n",
      "Test accuracy: 0.8577878103837472\n",
      "Emotion: disgust\n",
      "Test accuracy: 0.7584650112866818\n",
      "Emotion: fear\n",
      "Test accuracy: 0.9209932279909706\n",
      "Emotion: joy\n",
      "Test accuracy: 0.7979683972911964\n",
      "Emotion: love\n",
      "Test accuracy: 0.8893905191873589\n",
      "Emotion: optimism\n",
      "Test accuracy: 0.7663656884875847\n",
      "Emotion: pessimism\n",
      "Test accuracy: 0.8860045146726863\n",
      "Emotion: sadness\n",
      "Test accuracy: 0.7900677200902935\n",
      "Emotion: surprise\n",
      "Test accuracy: 0.9627539503386005\n",
      "Emotion: trust\n",
      "Test accuracy: 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "#C-Support Vector Classification.\n",
    "SVC_pipeline = Pipeline([\n",
    "               ('tfidf', TfidfVectorizer(stop_words=stop_words, max_df = 0.8)),\n",
    "    #integrated a calibrated classifier to enable predicted_proba\n",
    "               ('clf', CalibratedClassifierCV(LinearSVC())),\n",
    "           ])\n",
    "\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion: {}'.format(category))\n",
    "    # train the model\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy: {}'.format(accuracy_score(test[category], prediction)))\n",
    "    ### used predicted proba to save to no value data frame with same tweets and column headers\n",
    "    y_proba = SVC_pipeline.predict_proba(X_test)[:,1]\n",
    "    test_df_no_values[category] = y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@RanaAyyub @rajnathsingh Oh, hidden revenge and anger...I rememberthe time,she rebutted you.</td>\n",
       "      <td>0.999821</td>\n",
       "      <td>0.045523</td>\n",
       "      <td>0.888137</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>0.015030</td>\n",
       "      <td>0.212767</td>\n",
       "      <td>0.049603</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>0.018255</td>\n",
       "      <td>0.020512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm doing all this to make sure you smiling down on me bro</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>0.133957</td>\n",
       "      <td>0.186289</td>\n",
       "      <td>0.079062</td>\n",
       "      <td>0.924498</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.742139</td>\n",
       "      <td>0.066338</td>\n",
       "      <td>0.155026</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.062199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if not then #teamchristine bc all tana has done is provoke her by tweeting shady shit and trying to be a hard bitch begging for a fight</td>\n",
       "      <td>0.942420</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.829731</td>\n",
       "      <td>0.083766</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.025993</td>\n",
       "      <td>0.044811</td>\n",
       "      <td>0.081486</td>\n",
       "      <td>0.317104</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.024550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a #great start for #beginners to jump into auto #trading. PROFITABLE FX EA will give you full support, manuals &amp;amp; Team Viewer support.</td>\n",
       "      <td>0.229040</td>\n",
       "      <td>0.209044</td>\n",
       "      <td>0.372217</td>\n",
       "      <td>0.090401</td>\n",
       "      <td>0.446502</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.432084</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>0.171432</td>\n",
       "      <td>0.087032</td>\n",
       "      <td>0.094813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My best friends driving for the first time with me in the car #terrifying</td>\n",
       "      <td>0.190758</td>\n",
       "      <td>0.098758</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.536408</td>\n",
       "      <td>0.498999</td>\n",
       "      <td>0.088630</td>\n",
       "      <td>0.526639</td>\n",
       "      <td>0.059442</td>\n",
       "      <td>0.400151</td>\n",
       "      <td>0.043139</td>\n",
       "      <td>0.044164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey @SuperValuIRL #Fields in #skibbereen give your online delivery service a horrible name. 1.5 hours late on the 1 hour delivery window.</td>\n",
       "      <td>0.886056</td>\n",
       "      <td>0.185273</td>\n",
       "      <td>0.878423</td>\n",
       "      <td>0.334658</td>\n",
       "      <td>0.141843</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.101465</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.295737</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.041690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why have #Emmerdale had to rob #robron of having their first child together for that vile woman/cheating sl smh #bitter</td>\n",
       "      <td>0.856661</td>\n",
       "      <td>0.132491</td>\n",
       "      <td>0.829636</td>\n",
       "      <td>0.090743</td>\n",
       "      <td>0.123824</td>\n",
       "      <td>0.048926</td>\n",
       "      <td>0.107893</td>\n",
       "      <td>0.139817</td>\n",
       "      <td>0.464447</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.042761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@ThomasEWoods I would like to hear a podcast of you going off refuting her entire article. Extra indignation please.</td>\n",
       "      <td>0.356396</td>\n",
       "      <td>0.328359</td>\n",
       "      <td>0.213695</td>\n",
       "      <td>0.059089</td>\n",
       "      <td>0.124786</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.387332</td>\n",
       "      <td>0.052078</td>\n",
       "      <td>0.178995</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.039317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If I have to hear one more time how I am intimidate men... I'm going to explode! Why are guys these days so pussified?</td>\n",
       "      <td>0.723773</td>\n",
       "      <td>0.190538</td>\n",
       "      <td>0.327256</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.114956</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.363802</td>\n",
       "      <td>0.034060</td>\n",
       "      <td>0.033872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>depression sucksüòî</td>\n",
       "      <td>0.229510</td>\n",
       "      <td>0.056486</td>\n",
       "      <td>0.221747</td>\n",
       "      <td>0.157429</td>\n",
       "      <td>0.045045</td>\n",
       "      <td>0.031947</td>\n",
       "      <td>0.073581</td>\n",
       "      <td>0.208979</td>\n",
       "      <td>0.961885</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>0.027324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             Tweet  \\\n",
       "0  @RanaAyyub @rajnathsingh Oh, hidden revenge and anger...I rememberthe time,she rebutted you.                                                      \n",
       "1  I'm doing all this to make sure you smiling down on me bro                                                                                        \n",
       "2  if not then #teamchristine bc all tana has done is provoke her by tweeting shady shit and trying to be a hard bitch begging for a fight           \n",
       "3  It is a #great start for #beginners to jump into auto #trading. PROFITABLE FX EA will give you full support, manuals &amp; Team Viewer support.   \n",
       "4  My best friends driving for the first time with me in the car #terrifying                                                                         \n",
       "5  Hey @SuperValuIRL #Fields in #skibbereen give your online delivery service a horrible name. 1.5 hours late on the 1 hour delivery window.         \n",
       "6  Why have #Emmerdale had to rob #robron of having their first child together for that vile woman/cheating sl smh #bitter                           \n",
       "7  @ThomasEWoods I would like to hear a podcast of you going off refuting her entire article. Extra indignation please.                              \n",
       "8  If I have to hear one more time how I am intimidate men... I'm going to explode! Why are guys these days so pussified?                            \n",
       "9  depression sucksüòî                                                                                                                                 \n",
       "\n",
       "      anger  anticipation   disgust      fear       joy      love  optimism  \\\n",
       "0  0.999821  0.045523      0.888137  0.017862  0.023099  0.015030  0.212767   \n",
       "1  0.069404  0.133957      0.186289  0.079062  0.924498  0.296900  0.742139   \n",
       "2  0.942420  0.068860      0.829731  0.083766  0.038364  0.025993  0.044811   \n",
       "3  0.229040  0.209044      0.372217  0.090401  0.446502  0.049900  0.432084   \n",
       "4  0.190758  0.098758      0.328300  0.536408  0.498999  0.088630  0.526639   \n",
       "5  0.886056  0.185273      0.878423  0.334658  0.141843  0.017722  0.101465   \n",
       "6  0.856661  0.132491      0.829636  0.090743  0.123824  0.048926  0.107893   \n",
       "7  0.356396  0.328359      0.213695  0.059089  0.124786  0.027806  0.387332   \n",
       "8  0.723773  0.190538      0.327256  0.012396  0.258969  0.031416  0.114956   \n",
       "9  0.229510  0.056486      0.221747  0.157429  0.045045  0.031947  0.073581   \n",
       "\n",
       "   pessimism   sadness  surprise     trust  \n",
       "0  0.049603   0.078998  0.018255  0.020512  \n",
       "1  0.066338   0.155026  0.018939  0.062199  \n",
       "2  0.081486   0.317104  0.023900  0.024550  \n",
       "3  0.081376   0.171432  0.087032  0.094813  \n",
       "4  0.059442   0.400151  0.043139  0.044164  \n",
       "5  0.034676   0.295737  0.039641  0.041690  \n",
       "6  0.139817   0.464447  0.024838  0.042761  \n",
       "7  0.052078   0.178995  0.078454  0.039317  \n",
       "8  0.152359   0.363802  0.034060  0.033872  \n",
       "9  0.208979   0.961885  0.028509  0.027324  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data frame with added probability values for each emotion\n",
    "test_df_no_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7437923250564334\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8600451467268623\n",
      "Emotion disgust\n",
      "Test accuracy is 0.7110609480812641\n",
      "Emotion fear\n",
      "Test accuracy is 0.873589164785553\n",
      "Emotion joy\n",
      "Test accuracy is 0.7291196388261851\n",
      "Emotion love\n",
      "Test accuracy is 0.8510158013544018\n",
      "Emotion optimism\n",
      "Test accuracy is 0.6805869074492099\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8882618510158014\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7313769751693002\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9604966139954854\n",
      "Emotion trust\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', MultinomialNB(fit_prior=True, class_prior=None)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))\n",
    "    NB_pipeline.fit(X_train, train[category])    \n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7799097065462754\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8589164785553047\n",
      "Emotion disgust\n",
      "Test accuracy is 0.7426636568848759\n",
      "Emotion fear\n",
      "Test accuracy is 0.8939051918735892\n",
      "Emotion joy\n",
      "Test accuracy is 0.7799097065462754\n",
      "Emotion love\n",
      "Test accuracy is 0.8781038374717833\n",
      "Emotion optimism\n",
      "Test accuracy is 0.7528216704288939\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8848758465011287\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7753950338600452\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9627539503386005\n",
      "Emotion trust\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', LogisticRegression(solver='sag')),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    LogReg_pipeline.fit(X_train, train[category])    \n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7325056433408578\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8566591422121896\n",
      "Emotion disgust\n",
      "Test accuracy is 0.6952595936794582\n",
      "Emotion fear\n",
      "Test accuracy is 0.9063205417607223\n",
      "Emotion joy\n",
      "Test accuracy is 0.6941309255079007\n",
      "Emotion love\n",
      "Test accuracy is 0.8837471783295711\n",
      "Emotion optimism\n",
      "Test accuracy is 0.7234762979683973\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8871331828442438\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7799097065462754\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9627539503386005\n",
      "Emotion trust\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgboost_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', XGBClassifier()),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    xgboost_pipeline.fit(X_train, train[category])    \n",
    "    prediction = xgboost_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7708803611738149\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8589164785553047\n",
      "Emotion disgust\n",
      "Test accuracy is 0.7302483069977427\n",
      "Emotion fear\n",
      "Test accuracy is 0.9006772009029346\n",
      "Emotion joy\n",
      "Test accuracy is 0.7674943566591422\n",
      "Emotion love\n",
      "Test accuracy is 0.881489841986456\n",
      "Emotion optimism\n",
      "Test accuracy is 0.7483069977426636\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8871331828442438\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7742663656884876\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9627539503386005\n",
      "Emotion trust\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC_Nonlinear_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', SVC()),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    SVC_Nonlinear_pipeline.fit(X_train, train[category])    \n",
    "    prediction = SVC_Nonlinear_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Iteration 1, loss = 0.59716831\n",
      "Validation score: 0.786550\n",
      "Iteration 2, loss = 0.28167502\n",
      "Validation score: 0.780702\n",
      "Iteration 3, loss = 0.12490617\n",
      "Validation score: 0.770468\n",
      "Iteration 4, loss = 0.08120362\n",
      "Validation score: 0.769006\n",
      "Iteration 5, loss = 0.06364976\n",
      "Validation score: 0.763158\n",
      "Iteration 6, loss = 0.05650738\n",
      "Validation score: 0.769006\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.7629796839729119\n",
      "Emotion anticipation\n",
      "Iteration 1, loss = 0.48153683\n",
      "Validation score: 0.856725\n",
      "Iteration 2, loss = 0.29788813\n",
      "Validation score: 0.856725\n",
      "Iteration 3, loss = 0.20282777\n",
      "Validation score: 0.842105\n",
      "Iteration 4, loss = 0.13848714\n",
      "Validation score: 0.830409\n",
      "Iteration 5, loss = 0.08902768\n",
      "Validation score: 0.817251\n",
      "Iteration 6, loss = 0.06654522\n",
      "Validation score: 0.817251\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.8600451467268623\n",
      "Emotion disgust\n",
      "Iteration 1, loss = 0.60188361\n",
      "Validation score: 0.751462\n",
      "Iteration 2, loss = 0.29993410\n",
      "Validation score: 0.728070\n",
      "Iteration 3, loss = 0.15096441\n",
      "Validation score: 0.725146\n",
      "Iteration 4, loss = 0.10270702\n",
      "Validation score: 0.710526\n",
      "Iteration 5, loss = 0.08449178\n",
      "Validation score: 0.723684\n",
      "Iteration 6, loss = 0.07741592\n",
      "Validation score: 0.714912\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.7483069977426636\n",
      "Emotion fear\n",
      "Iteration 1, loss = 0.47928734\n",
      "Validation score: 0.818713\n",
      "Iteration 2, loss = 0.27065031\n",
      "Validation score: 0.849415\n",
      "Iteration 3, loss = 0.13902708\n",
      "Validation score: 0.847953\n",
      "Iteration 4, loss = 0.06558085\n",
      "Validation score: 0.842105\n",
      "Iteration 5, loss = 0.04268484\n",
      "Validation score: 0.834795\n",
      "Iteration 6, loss = 0.03330020\n",
      "Validation score: 0.839181\n",
      "Iteration 7, loss = 0.02880583\n",
      "Validation score: 0.836257\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.8927765237020316\n",
      "Emotion joy\n",
      "Iteration 1, loss = 0.57135946\n",
      "Validation score: 0.824561\n",
      "Iteration 2, loss = 0.23856646\n",
      "Validation score: 0.817251\n",
      "Iteration 3, loss = 0.10437225\n",
      "Validation score: 0.809942\n",
      "Iteration 4, loss = 0.06622784\n",
      "Validation score: 0.804094\n",
      "Iteration 5, loss = 0.05109682\n",
      "Validation score: 0.808480\n",
      "Iteration 6, loss = 0.04523990\n",
      "Validation score: 0.807018\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.7821670428893905\n",
      "Emotion love\n",
      "Iteration 1, loss = 0.42792679\n",
      "Validation score: 0.897661\n",
      "Iteration 2, loss = 0.21130339\n",
      "Validation score: 0.903509\n",
      "Iteration 3, loss = 0.12843982\n",
      "Validation score: 0.900585\n",
      "Iteration 4, loss = 0.07251245\n",
      "Validation score: 0.899123\n",
      "Iteration 5, loss = 0.04678883\n",
      "Validation score: 0.893275\n",
      "Iteration 6, loss = 0.03750028\n",
      "Validation score: 0.894737\n",
      "Iteration 7, loss = 0.03261213\n",
      "Validation score: 0.896199\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.8724604966139955\n",
      "Emotion optimism\n",
      "Iteration 1, loss = 0.58481239\n",
      "Validation score: 0.726608\n",
      "Iteration 2, loss = 0.35524258\n",
      "Validation score: 0.783626\n",
      "Iteration 3, loss = 0.18538109\n",
      "Validation score: 0.770468\n",
      "Iteration 4, loss = 0.10270614\n",
      "Validation score: 0.754386\n",
      "Iteration 5, loss = 0.07570974\n",
      "Validation score: 0.745614\n",
      "Iteration 6, loss = 0.06483483\n",
      "Validation score: 0.747076\n",
      "Iteration 7, loss = 0.05783084\n",
      "Validation score: 0.742690\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.7573363431151241\n",
      "Emotion pessimism\n",
      "Iteration 1, loss = 0.46125161\n",
      "Validation score: 0.883041\n",
      "Iteration 2, loss = 0.27204594\n",
      "Validation score: 0.883041\n",
      "Iteration 3, loss = 0.18772562\n",
      "Validation score: 0.871345\n",
      "Iteration 4, loss = 0.12829207\n",
      "Validation score: 0.849415\n",
      "Iteration 5, loss = 0.08340724\n",
      "Validation score: 0.839181\n",
      "Iteration 6, loss = 0.05999838\n",
      "Validation score: 0.836257\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.8871331828442438\n",
      "Emotion sadness\n",
      "Iteration 1, loss = 0.59414870\n",
      "Validation score: 0.714912\n",
      "Iteration 2, loss = 0.37834976\n",
      "Validation score: 0.783626\n",
      "Iteration 3, loss = 0.21101777\n",
      "Validation score: 0.770468\n",
      "Iteration 4, loss = 0.13074753\n",
      "Validation score: 0.754386\n",
      "Iteration 5, loss = 0.10286612\n",
      "Validation score: 0.744152\n",
      "Iteration 6, loss = 0.09159394\n",
      "Validation score: 0.745614\n",
      "Iteration 7, loss = 0.08195624\n",
      "Validation score: 0.744152\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.7652370203160271\n",
      "Emotion surprise\n",
      "Iteration 1, loss = 0.32836568\n",
      "Validation score: 0.947368\n",
      "Iteration 2, loss = 0.15105693\n",
      "Validation score: 0.947368\n",
      "Iteration 3, loss = 0.10061013\n",
      "Validation score: 0.945906\n",
      "Iteration 4, loss = 0.06900825\n",
      "Validation score: 0.941520\n",
      "Iteration 5, loss = 0.04629870\n",
      "Validation score: 0.929825\n",
      "Iteration 6, loss = 0.03004225\n",
      "Validation score: 0.929825\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.9604966139954854\n",
      "Emotion trust\n",
      "Iteration 1, loss = 0.36474239\n",
      "Validation score: 0.947368\n",
      "Iteration 2, loss = 0.15672290\n",
      "Validation score: 0.947368\n",
      "Iteration 3, loss = 0.10484006\n",
      "Validation score: 0.948830\n",
      "Iteration 4, loss = 0.07189741\n",
      "Validation score: 0.945906\n",
      "Iteration 5, loss = 0.05588322\n",
      "Validation score: 0.942982\n",
      "Iteration 6, loss = 0.04762834\n",
      "Validation score: 0.941520\n",
      "Iteration 7, loss = 0.03742577\n",
      "Validation score: 0.940058\n",
      "Iteration 8, loss = 0.02928603\n",
      "Validation score: 0.938596\n",
      "Validation score did not improve more than tol=0.000100 for 4 consecutive epochs. Stopping.\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Multi-layer Perceptron classifier\n",
    "#This model optimizes the log-loss function using LBFGS or stochastic gradient descent.\n",
    "#default solver is ADAM \n",
    "\n",
    "NN_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', MLPClassifier(hidden_layer_sizes = (100), learning_rate_init= 0.005, \n",
    "                                      learning_rate = 'adaptive', n_iter_no_change= 4, \n",
    "                                      verbose=True, early_stopping=True)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    NN_pipeline.fit(X_train, train[category])    \n",
    "    prediction = NN_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7234762979683973\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8498871331828443\n",
      "Emotion disgust\n",
      "Test accuracy is 0.698645598194131\n",
      "Emotion fear\n",
      "Test accuracy is 0.8566591422121896\n",
      "Emotion joy\n",
      "Test accuracy is 0.718961625282167\n",
      "Emotion love\n",
      "Test accuracy is 0.8724604966139955\n",
      "Emotion optimism\n",
      "Test accuracy is 0.6896162528216704\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8724604966139955\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7302483069977427\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9616252821670429\n",
      "Emotion trust\n",
      "Test accuracy is 0.9503386004514672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', KNeighborsClassifier()),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    KNN_pipeline.fit(X_train, train[category])    \n",
    "    prediction = KNN_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion anger\n",
      "Test accuracy is 0.7799097065462754\n",
      "Emotion anticipation\n",
      "Test accuracy is 0.8611738148984198\n",
      "Emotion disgust\n",
      "Test accuracy is 0.7505643340857788\n",
      "Emotion fear\n",
      "Test accuracy is 0.9209932279909706\n",
      "Emotion joy\n",
      "Test accuracy is 0.7821670428893905\n",
      "Emotion love\n",
      "Test accuracy is 0.8792325056433409\n",
      "Emotion optimism\n",
      "Test accuracy is 0.7279909706546276\n",
      "Emotion pessimism\n",
      "Test accuracy is 0.8871331828442438\n",
      "Emotion sadness\n",
      "Test accuracy is 0.7821670428893905\n",
      "Emotion surprise\n",
      "Test accuracy is 0.9627539503386005\n",
      "Emotion trust\n",
      "Test accuracy is 0.9514672686230248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', RandomForestClassifier()),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion {}'.format(category))    \n",
    "    RF_pipeline.fit(X_train, train[category])    \n",
    "    prediction = RF_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so ryanair site crashes everytime try to book how do they help tell me there nothing wrong amp hang up furious helpless simoncalder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theme of week ask the lord for strength amp perspective to persevere in integrity and effort despite being disheartened amp disappointed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why announcing so late it will be hard to make it from manchester and organising day off sad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the greatest happiness is seeing someone you like stay happy daidouji tomoyo cardcaptor sakura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omg so grateful to have an education but ive been back at school for two days and my back hurts im exhausted and breaking out already smiling face with heart eyes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                Tweet  \\\n",
       "0  so ryanair site crashes everytime try to book how do they help tell me there nothing wrong amp hang up furious helpless simoncalder                                  \n",
       "1  theme of week ask the lord for strength amp perspective to persevere in integrity and effort despite being disheartened amp disappointed                             \n",
       "2  why announcing so late it will be hard to make it from manchester and organising day off sad                                                                         \n",
       "3  the greatest happiness is seeing someone you like stay happy daidouji tomoyo cardcaptor sakura                                                                       \n",
       "4  omg so grateful to have an education but ive been back at school for two days and my back hurts im exhausted and breaking out already smiling face with heart eyes   \n",
       "\n",
       "   anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "1 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "2 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "3 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "4 NaN    NaN           NaN      NaN   NaN  NaN   NaN       NaN          \n",
       "\n",
       "   sadness  surprise  trust  \n",
       "0 NaN      NaN       NaN     \n",
       "1 NaN      NaN       NaN     \n",
       "2 NaN      NaN       NaN     \n",
       "3 NaN      NaN       NaN     \n",
       "4 NaN      NaN       NaN     "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created smaller unseen data set with no predicted values, only label columns included\n",
    "\n",
    "df_unseen = pd.read_csv('unseen.csv')\n",
    "df_unseen['Tweet'] = df_unseen['Tweet'].map(lambda com : convert_emojis(com))\n",
    "df_unseen['Tweet'] = df_unseen['Tweet'].map(lambda com : clean_text(com))\n",
    "df_unseen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "X_unseen = df_unseen.Tweet\n",
    "print(X_unseen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc pipeline training needed to be included to get actual predicted outcome from model\n",
    "\n",
    "for category in categories:\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    new_proba = SVC_pipeline.predict_proba(X_unseen)[:,1]\n",
    "    df_unseen[category] = new_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so ryanair site crashes everytime try to book how do they help tell me there nothing wrong amp hang up furious helpless simoncalder</td>\n",
       "      <td>0.687843</td>\n",
       "      <td>0.160639</td>\n",
       "      <td>0.541247</td>\n",
       "      <td>0.076307</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.136074</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>0.237131</td>\n",
       "      <td>0.040238</td>\n",
       "      <td>0.045809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theme of week ask the lord for strength amp perspective to persevere in integrity and effort despite being disheartened amp disappointed</td>\n",
       "      <td>0.060513</td>\n",
       "      <td>0.126585</td>\n",
       "      <td>0.158127</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>0.210805</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.207492</td>\n",
       "      <td>0.407167</td>\n",
       "      <td>0.590876</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.045527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why announcing so late it will be hard to make it from manchester and organising day off sad</td>\n",
       "      <td>0.042662</td>\n",
       "      <td>0.070726</td>\n",
       "      <td>0.148653</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.015671</td>\n",
       "      <td>0.014715</td>\n",
       "      <td>0.075524</td>\n",
       "      <td>0.107883</td>\n",
       "      <td>0.915479</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.020998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the greatest happiness is seeing someone you like stay happy daidouji tomoyo cardcaptor sakura</td>\n",
       "      <td>0.038587</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.992182</td>\n",
       "      <td>0.409950</td>\n",
       "      <td>0.888868</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.029090</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.071317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>omg so grateful to have an education but ive been back at school for two days and my back hurts im exhausted and breaking out already smiling face with heart eyes</td>\n",
       "      <td>0.074810</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.100174</td>\n",
       "      <td>0.323614</td>\n",
       "      <td>0.763688</td>\n",
       "      <td>0.166712</td>\n",
       "      <td>0.486084</td>\n",
       "      <td>0.192444</td>\n",
       "      <td>0.383971</td>\n",
       "      <td>0.037798</td>\n",
       "      <td>0.036075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>because of your smile you make the life more beautiful</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>0.093586</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.992907</td>\n",
       "      <td>0.749881</td>\n",
       "      <td>0.962362</td>\n",
       "      <td>0.041675</td>\n",
       "      <td>0.137449</td>\n",
       "      <td>0.030407</td>\n",
       "      <td>0.081258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mashable for some reason this has filled me with delight see auntie laugh</td>\n",
       "      <td>0.061592</td>\n",
       "      <td>0.160958</td>\n",
       "      <td>0.031709</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.992198</td>\n",
       "      <td>0.333250</td>\n",
       "      <td>0.572994</td>\n",
       "      <td>0.114474</td>\n",
       "      <td>0.078024</td>\n",
       "      <td>0.101171</td>\n",
       "      <td>0.049732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lovemyffajacket facetime we can still annoy you face with tears of joy</td>\n",
       "      <td>0.210157</td>\n",
       "      <td>0.093034</td>\n",
       "      <td>0.169168</td>\n",
       "      <td>0.169506</td>\n",
       "      <td>0.726335</td>\n",
       "      <td>0.142944</td>\n",
       "      <td>0.218715</td>\n",
       "      <td>0.092466</td>\n",
       "      <td>0.212134</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.041358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and shouldve cut them off the moment started hurting myself over them</td>\n",
       "      <td>0.541620</td>\n",
       "      <td>0.094003</td>\n",
       "      <td>0.149242</td>\n",
       "      <td>0.226306</td>\n",
       "      <td>0.126204</td>\n",
       "      <td>0.086353</td>\n",
       "      <td>0.119188</td>\n",
       "      <td>0.254522</td>\n",
       "      <td>0.438933</td>\n",
       "      <td>0.026243</td>\n",
       "      <td>0.027519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vesciodiana you forgot laughter as well red heart red heart red heart</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>0.152533</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>0.059902</td>\n",
       "      <td>0.977271</td>\n",
       "      <td>0.879410</td>\n",
       "      <td>0.392351</td>\n",
       "      <td>0.037617</td>\n",
       "      <td>0.167348</td>\n",
       "      <td>0.034842</td>\n",
       "      <td>0.053683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                Tweet  \\\n",
       "0  so ryanair site crashes everytime try to book how do they help tell me there nothing wrong amp hang up furious helpless simoncalder                                  \n",
       "1  theme of week ask the lord for strength amp perspective to persevere in integrity and effort despite being disheartened amp disappointed                             \n",
       "2  why announcing so late it will be hard to make it from manchester and organising day off sad                                                                         \n",
       "3  the greatest happiness is seeing someone you like stay happy daidouji tomoyo cardcaptor sakura                                                                       \n",
       "4  omg so grateful to have an education but ive been back at school for two days and my back hurts im exhausted and breaking out already smiling face with heart eyes   \n",
       "5  because of your smile you make the life more beautiful                                                                                                               \n",
       "6  mashable for some reason this has filled me with delight see auntie laugh                                                                                            \n",
       "7  lovemyffajacket facetime we can still annoy you face with tears of joy                                                                                               \n",
       "8  and shouldve cut them off the moment started hurting myself over them                                                                                                \n",
       "9  vesciodiana you forgot laughter as well red heart red heart red heart                                                                                                \n",
       "\n",
       "      anger  anticipation   disgust      fear       joy      love  optimism  \\\n",
       "0  0.687843  0.160639      0.541247  0.076307  0.026194  0.022830  0.136074   \n",
       "1  0.060513  0.126585      0.158127  0.394120  0.210805  0.019894  0.207492   \n",
       "2  0.042662  0.070726      0.148653  0.016435  0.015671  0.014715  0.075524   \n",
       "3  0.038587  0.076730      0.079866  0.010128  0.992182  0.409950  0.888868   \n",
       "4  0.074810  0.062798      0.100174  0.323614  0.763688  0.166712  0.486084   \n",
       "5  0.010375  0.093586      0.034155  0.009071  0.992907  0.749881  0.962362   \n",
       "6  0.061592  0.160958      0.031709  0.016611  0.992198  0.333250  0.572994   \n",
       "7  0.210157  0.093034      0.169168  0.169506  0.726335  0.142944  0.218715   \n",
       "8  0.541620  0.094003      0.149242  0.226306  0.126204  0.086353  0.119188   \n",
       "9  0.052277  0.152533      0.022640  0.059902  0.977271  0.879410  0.392351   \n",
       "\n",
       "   pessimism   sadness  surprise     trust  \n",
       "0  0.067019   0.237131  0.040238  0.045809  \n",
       "1  0.407167   0.590876  0.027548  0.045527  \n",
       "2  0.107883   0.915479  0.012496  0.020998  \n",
       "3  0.047500   0.029090  0.033910  0.071317  \n",
       "4  0.192444   0.383971  0.037798  0.036075  \n",
       "5  0.041675   0.137449  0.030407  0.081258  \n",
       "6  0.114474   0.078024  0.101171  0.049732  \n",
       "7  0.092466   0.212134  0.041595  0.041358  \n",
       "8  0.254522   0.438933  0.026243  0.027519  \n",
       "9  0.037617   0.167348  0.034842  0.053683  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unseen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
