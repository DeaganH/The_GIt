{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E-c-En-train.csv')\n",
    "df_test = pd.read_csv('E-c-En-dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Tweets per emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>no. of tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anticipation</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disgust</td>\n",
       "      <td>2602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fear</td>\n",
       "      <td>1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>love</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>optimism</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pessimism</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sadness</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surprise</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>trust</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Emotion  no. of tweets\n",
       "0          anger           2544\n",
       "1   anticipation            978\n",
       "2        disgust           2602\n",
       "3           fear           1242\n",
       "4            joy           2477\n",
       "5           love            700\n",
       "6       optimism           1984\n",
       "7      pessimism            795\n",
       "8        sadness           2008\n",
       "9       surprise            361\n",
       "10         trust            357"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.drop(['ID', 'Tweet'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_new.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['Emotion', 'no. of tweets'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.029833284586136297\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df[(df['anger']==0) & (df['anticipation']==0) & (df['disgust']==0) & (df['fear']== 0) & (df['joy']==0) & (df['love']==0) & (df['optimism']==0) & (df['pessimism']==0) & (df['sadness']==0) & (df['surprise']==0) & (df['trust']==0)]) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of comments that are not labelled:\n",
      "0.0038022813688212928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DextrousD\\Anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('Percentage of comments that are not labelled:')\n",
    "print(len(df_test[(df['anger']==0) & (df['anticipation']==0) & (df['disgust']==0) & (df['fear']== 0) & (df['joy']==0) & (df['love']==0) & (df['optimism']==0) & (df['pessimism']==0) & (df['sadness']==0) & (df['surprise']==0) & (df['trust']==0)]) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ‚ÄúWorry is a down payment on a problem you may never have'. ¬†Joyce Meyer.  #motivation #leadership #worry                        \n",
       "1    Whatever you decide to do make sure it makes you #happy.                                                                        \n",
       "2    @Max_Kellerman  it also helps that the majority of NFL coaching is inept. Some of Bill O'Brien's play calling was wow, ! #GOPATS\n",
       "3    Accept the challenges so that you can literally even feel the exhilaration of victory.' -- George S. Patton üê∂                   \n",
       "4    My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs                              \n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df['Tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "# Function for converting emojis into words\n",
    "def convert_emojis(text):\n",
    "    text = emoji.demojize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].map(lambda com : convert_emojis(com))\n",
    "df_test['Tweet'] = df_test['Tweet'].map(lambda com : convert_emojis(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text) \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = re.sub('_', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tweet'] = df['Tweet'].map(lambda com : clean_text(com))\n",
    "df_test['Tweet'] = df_test['Tweet'].map(lambda com : clean_text(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    making that yearly transition from excited and hopeful college returner to sick and exhausted pessimist college                                     \n",
       "11    and it  hard to dance with  devil on your back nso shake him off                                                                                    \n",
       "12    tiller and breezy should do  collab album rapping and singing prolly be fire                                                                        \n",
       "13    to the girl that just hit my car not only did she get lucky  no scratch but also from being spared the wrath of sleep deprived kait upside down face\n",
       "14    bt uk broadband is shocking regretting signing up now angry shouldofgonewithvirgin                                                                  \n",
       "15    people you need to look up the definition of protest what you are doing is not protesting is called vandalism angry stop                            \n",
       "16    bitchesthecat look at those teef growl                                                                                                              \n",
       "17    star trek online has  update to download oh fuming yay                                                                                              \n",
       "18    the bitter the battle the sweeter the victory                                                                                                       \n",
       "19    cant stop  finished dejected luckily no one is in the bathroom so  go to  stall and wait until my pants are dry                                     \n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df\n",
    "test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6838,)\n",
      "(886,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.Tweet\n",
    "X_test = test.Tweet\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['anger','anticipation','disgust','fear','joy','love','optimism','pessimism','sadness','surprise','trust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion: anger\n",
      "Test accuracy: 0.791196388261851\n",
      "Emotion: anticipation\n",
      "Test accuracy: 0.8498871331828443\n",
      "Emotion: disgust\n",
      "Test accuracy: 0.7641083521444695\n",
      "Emotion: fear\n",
      "Test accuracy: 0.9187358916478555\n",
      "Emotion: joy\n",
      "Test accuracy: 0.801354401805869\n",
      "Emotion: love\n",
      "Test accuracy: 0.8961625282167043\n",
      "Emotion: optimism\n",
      "Test accuracy: 0.781038374717833\n",
      "Emotion: pessimism\n",
      "Test accuracy: 0.8860045146726863\n",
      "Emotion: sadness\n",
      "Test accuracy: 0.7844243792325056\n",
      "Emotion: surprise\n",
      "Test accuracy: 0.963882618510158\n",
      "Emotion: trust\n",
      "Test accuracy: 0.9492099322799097\n"
     ]
    }
   ],
   "source": [
    "#C-Support Vector Classification.\n",
    "SVC_pipeline = Pipeline([\n",
    "               ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range = (1, 2))),\n",
    "               ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('Emotion: {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy: {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#model = SVC_pipeline\n",
    "#filename = 'english_model.sav'\n",
    "#pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
